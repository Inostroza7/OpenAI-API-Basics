{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inostroza7/OpenAI-LangChain-Basics/blob/main/OpenAI_LangChain_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68ec3b08",
      "metadata": {
        "id": "68ec3b08"
      },
      "source": [
        "# ü§ñüåü OpenAI & üåüü¶úÔ∏èüîó LangChain üìö Basics\n",
        "\n",
        "## üåà Descripci√≥n üìö\n",
        "\n",
        "Este curso te proporciona las habilidades esenciales para dominar tanto la API de OpenAI como el ecosistema de LangChain.\n",
        "A trav√©s de una combinaci√≥n de teor√≠a y pr√°ctica, te prepararemos para implementar soluciones de vanguardia en inteligencia artificial. üöÄ\n",
        "\n",
        "## üõ† Requisitos ‚öôÔ∏è\n",
        "\n",
        "- Python 3.x üêç\n",
        "- Acceso a la API de OpenAI ü§ñ\n",
        "- Conocimientos b√°sicos de programaci√≥n üíª\n",
        "\n",
        "## üöÄ ¬øListo para empezar? üåü\n",
        "\n",
        "¬°Vamos all√°! üí•"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a925b966",
      "metadata": {
        "id": "a925b966"
      },
      "source": [
        "### ü§ñ API de OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ec987fd",
      "metadata": {
        "id": "3ec987fd"
      },
      "source": [
        "#### Instalar OpenAI üåê"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b990ed8",
      "metadata": {
        "id": "0b990ed8"
      },
      "outputs": [],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3eb069e",
      "metadata": {
        "id": "e3eb069e"
      },
      "source": [
        "#### Importa la libreria üìö"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a54a2c8",
      "metadata": {
        "id": "8a54a2c8"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69cd13f6",
      "metadata": {
        "id": "69cd13f6"
      },
      "source": [
        "#### Configuraci√≥n del entorno üõ†Ô∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09df3623",
      "metadata": {
        "id": "09df3623"
      },
      "outputs": [],
      "source": [
        "openai.api_key = 'Ingresa aqu√≠ tu API Key de OpenAI'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cf82f36",
      "metadata": {
        "id": "6cf82f36"
      },
      "source": [
        "#### Tu primer Chatbot üëã"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff6842ee",
      "metadata": {
        "id": "ff6842ee"
      },
      "source": [
        "Ingresa tu prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c82e2683",
      "metadata": {
        "id": "c82e2683"
      },
      "outputs": [],
      "source": [
        "prompt = 'Hola Chatbot'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579bf1bc",
      "metadata": {
        "id": "579bf1bc"
      },
      "source": [
        "- System: contexto de fondo √∫til que le indica a la IA qu√© hacer\n",
        "- Human: mensajes que pretenden representar al usuario.\n",
        "- AI: mensajes que muestran con qu√© respondi√≥ la IA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd95924f",
      "metadata": {
        "id": "cd95924f"
      },
      "outputs": [],
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},],\n",
        "    temperature=1\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60354338",
      "metadata": {
        "id": "60354338"
      },
      "outputs": [],
      "source": [
        "response.choices[0].message['content']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c979b226",
      "metadata": {
        "id": "c979b226"
      },
      "source": [
        "### ü¶úÔ∏èüîó LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ac1918",
      "metadata": {
        "id": "c6ac1918"
      },
      "source": [
        "#### Instalar Langchain üåê"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fe40412",
      "metadata": {
        "id": "9fe40412"
      },
      "outputs": [],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf6f4d91",
      "metadata": {
        "id": "bf6f4d91"
      },
      "source": [
        "#### LLM (LangChain Language Model) üó®Ô∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68443ad1",
      "metadata": {
        "id": "68443ad1"
      },
      "source": [
        "Define tu LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe9a742",
      "metadata": {
        "id": "bfe9a742"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "395e939a",
      "metadata": {
        "id": "395e939a"
      },
      "source": [
        "Prueba tu LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332e1a47",
      "metadata": {
        "id": "332e1a47"
      },
      "outputs": [],
      "source": [
        "prompt = 'Hola, c√≥mo est√°s??'\n",
        "print(llm(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f14801c0",
      "metadata": {
        "id": "f14801c0"
      },
      "source": [
        "Importa las librerias del chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0180ee57",
      "metadata": {
        "id": "0180ee57"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import SystemMessage, HumanMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "237cd421",
      "metadata": {
        "id": "237cd421"
      },
      "outputs": [],
      "source": [
        "prompt = 'Hola c√≥mo est√°s?'\n",
        "chat = ChatOpenAI(model='gpt-3.5-turbo',temperature=0.3)\n",
        "messages = [\n",
        "    SystemMessage(content='You are a helpful assistant'),\n",
        "    HumanMessage(content=prompt)\n",
        "]\n",
        "response = chat(messages)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "326de69f",
      "metadata": {
        "id": "326de69f"
      },
      "source": [
        "Obt√©n s√≥lo el texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62816af2",
      "metadata": {
        "id": "62816af2"
      },
      "outputs": [],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4cc354",
      "metadata": {
        "id": "3b4cc354"
      },
      "source": [
        "#### Embeddings üìñ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebc8b990",
      "metadata": {
        "id": "ebc8b990"
      },
      "source": [
        "Definimos la funci√≥n para cargar el documento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77c6e73f",
      "metadata": {
        "id": "77c6e73f"
      },
      "outputs": [],
      "source": [
        "def load_document(file):\n",
        "    import os\n",
        "    name, extension = os.path.splitext(file)\n",
        "\n",
        "    if extension == '.pdf':\n",
        "        from langchain.document_loaders import PyPDFLoader\n",
        "        print(f'Loading {file}')\n",
        "        loader = PyPDFLoader(file)\n",
        "    elif extension == '.docx':\n",
        "        from langchain.document_loaders import Docx2txtLoader\n",
        "        print(f'Loading {file}')\n",
        "        loader = Docx2txtLoader(file)\n",
        "    elif extension == '.txt':\n",
        "        from langchain.document_loaders import TextLoader\n",
        "        loader = TextLoader(file)\n",
        "    else:\n",
        "        print('El formato del archivo no es v√°lido')\n",
        "        return None\n",
        "\n",
        "    data = loader.load()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e0595bc",
      "metadata": {
        "id": "6e0595bc"
      },
      "source": [
        "Definimos la funci√≥n para hacer los Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "230f196d",
      "metadata": {
        "id": "230f196d"
      },
      "outputs": [],
      "source": [
        "def chunk_data(data, chunk_size=500, chunk_overlap=0):\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    chunks = text_splitter.split_documents(data)\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d52baf3",
      "metadata": {
        "id": "4d52baf3"
      },
      "source": [
        "Definimos la funci√≥n para crear los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6e91d0",
      "metadata": {
        "id": "ae6e91d0"
      },
      "outputs": [],
      "source": [
        "def create_embeddings(chunks):\n",
        "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    from langchain.vectorstores import Chroma\n",
        "    vector_store = Chroma.from_documents(chunks, embeddings)\n",
        "    return vector_store"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4b06654",
      "metadata": {
        "id": "f4b06654"
      },
      "source": [
        "Definimos nuestro Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5676167",
      "metadata": {
        "id": "e5676167"
      },
      "outputs": [],
      "source": [
        "def ask_and_get_answer(vector_store, q, k=3):\n",
        "    from langchain.chains import RetrievalQA\n",
        "    from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.2)\n",
        "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})\n",
        "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "    answer = chain.run(q)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a112d7cd",
      "metadata": {
        "id": "a112d7cd"
      },
      "source": [
        "Carga tu PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eda4ba7",
      "metadata": {
        "id": "1eda4ba7"
      },
      "outputs": [],
      "source": [
        "data = load_document('Oppenheimer.pdf')\n",
        "print(f'El documento tiene {len(data)} paginas')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560807ac",
      "metadata": {
        "id": "560807ac"
      },
      "outputs": [],
      "source": [
        "chunks = chunk_data(data)\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0884e06d",
      "metadata": {
        "id": "0884e06d"
      },
      "source": [
        "Crea los embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "668dfcc8",
      "metadata": {
        "id": "668dfcc8"
      },
      "outputs": [],
      "source": [
        "vector_store = create_embeddings(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d1e5a2e",
      "metadata": {
        "id": "2d1e5a2e"
      },
      "source": [
        "Prueba el Chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3e1961f",
      "metadata": {
        "id": "f3e1961f"
      },
      "outputs": [],
      "source": [
        "\n",
        "q = 'Quien protagoniz√≥ la pel√≠cula Oppenhemier'\n",
        "k = 3\n",
        "answer = ask_and_get_answer(vector_store, q, k)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f14eb59a",
      "metadata": {
        "id": "f14eb59a"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "i = 1\n",
        "print('Escribe Chao, Salir o Adios para salir.')\n",
        "while True:\n",
        "    q = input(f'Pregunta #{i}: ')\n",
        "    i = i+1\n",
        "    if q.lower() in  ['salir', 'chao', 'adios']:\n",
        "        print('Hasta luego!')\n",
        "        time.sleep(2)\n",
        "        break\n",
        "\n",
        "    answer = ask_and_get_answer(vector_store, q, 5)\n",
        "    print(answer)\n",
        "    print(f'\\n {\"-\"*50} \\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1197dc",
      "metadata": {
        "id": "0f1197dc"
      },
      "source": [
        "#### Memoria üß†"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a445664f",
      "metadata": {
        "id": "a445664f"
      },
      "source": [
        "Definimos nuestro contador de Tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33848be5",
      "metadata": {
        "id": "33848be5"
      },
      "outputs": [],
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "def count_tokens(chain, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = chain.run(query)\n",
        "        print(f'Has utilizado {cb.total_tokens} tokens')\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40531e5d",
      "metadata": {
        "id": "40531e5d"
      },
      "source": [
        "Definimos nuestro modelo y cadena"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzhjgggKRiNM"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "\ttemperature=0,\n",
        "\tmodel_name=\"gpt-3.5-turbo\"\n",
        ")\n",
        "\n",
        "conversation = ConversationChain(llm=llm)"
      ],
      "id": "MzhjgggKRiNM"
    },
    {
      "cell_type": "markdown",
      "id": "334ac9a5",
      "metadata": {
        "id": "334ac9a5"
      },
      "source": [
        "ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64dd47f8",
      "metadata": {
        "id": "64dd47f8"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "\n",
        "conversation_buf = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationBufferMemory()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35721160",
      "metadata": {
        "id": "35721160"
      },
      "outputs": [],
      "source": [
        "conv_buf = conversation_buf('Hola, c√≥mo est√°s?')\n",
        "print(conv_buf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c8d147",
      "metadata": {
        "id": "b6c8d147"
      },
      "outputs": [],
      "source": [
        "count_tokens(conversation_buf, 'Que artistas tienen mi nombre?')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39a72819",
      "metadata": {
        "id": "39a72819"
      },
      "source": [
        "ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96ca0e18",
      "metadata": {
        "id": "96ca0e18"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "conversation_bufw = ConversationChain(\n",
        "\tllm=llm,\n",
        "\tmemory=ConversationBufferWindowMemory(k=2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "083e5be8",
      "metadata": {
        "id": "083e5be8"
      },
      "outputs": [],
      "source": [
        "count_tokens(conversation_bufw,\"Cu√°l es mi nombre!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe501c9e",
      "metadata": {
        "id": "fe501c9e"
      },
      "outputs": [],
      "source": [
        "bufw_history = conversation_bufw.memory.load_memory_variables(\n",
        "    inputs=[]\n",
        ")['history']\n",
        "print(bufw_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ab4a981",
      "metadata": {
        "id": "6ab4a981"
      },
      "source": [
        "#### Agentes üïµÔ∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de78d8e0",
      "metadata": {
        "id": "de78d8e0"
      },
      "source": [
        "Definimos el LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2abb4485",
      "metadata": {
        "id": "2abb4485"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "\n",
        "llm = OpenAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gpt-3.5-turbo\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff9387f",
      "metadata": {
        "id": "1ff9387f"
      },
      "source": [
        "Definimos nuestra Tool de Calculadora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96bffb96",
      "metadata": {
        "id": "96bffb96"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMMathChain\n",
        "from langchain.agents import Tool\n",
        "\n",
        "llm_math = LLMMathChain(llm=llm)\n",
        "\n",
        "math_tool = Tool(\n",
        "    name='Calculator',\n",
        "    func=llm_math.run,\n",
        "    description='Useful for when you need to answer questions about math.')\n",
        "\n",
        "tools = [math_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b128875c",
      "metadata": {
        "id": "b128875c"
      },
      "source": [
        "Iniciamos nuestro agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e65dab",
      "metadata": {
        "id": "20e65dab"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import initialize_agent\n",
        "\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea8e0bae",
      "metadata": {
        "id": "ea8e0bae"
      },
      "source": [
        "Le preguntamos nuestro c√°lculo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "205e1b34",
      "metadata": {
        "id": "205e1b34"
      },
      "outputs": [],
      "source": [
        "zero_shot_agent(\"Cuanto es(4.5*2.1)^2.2?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f1038bc",
      "metadata": {
        "id": "4f1038bc"
      },
      "source": [
        "Prueba el agente con un problema matem√°tico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8ba4b9a",
      "metadata": {
        "id": "c8ba4b9a"
      },
      "outputs": [],
      "source": [
        "zero_shot_agent(\"Si Mar√≠a tiene cuatro manzanas y Jorge trae dos cajas y media de manzanas\"\n",
        "                \"(cada caja tiene 8 manzanas) cuantas manzanas tendr√° Mar√≠a en total?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96b6b00",
      "metadata": {
        "id": "e96b6b00"
      },
      "source": [
        "#### Tools üõ†Ô∏è"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b852d7a",
      "metadata": {
        "id": "5b852d7a"
      },
      "source": [
        "Instalamos el m√≥dulo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c24243",
      "metadata": {
        "id": "c8c24243"
      },
      "outputs": [],
      "source": [
        "pip install duckduckgo-search"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22522ae4",
      "metadata": {
        "id": "22522ae4"
      },
      "source": [
        "Definimos nuestra herramienta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce12e3c9",
      "metadata": {
        "id": "ce12e3c9"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import DuckDuckGoSearchRun\n",
        "\n",
        "search = DuckDuckGoSearchRun()\n",
        "\n",
        "searchTool = Tool(\n",
        "                name=\"Intermediate Answer\",\n",
        "                func=search.run,\n",
        "                description=\"useful for when you need to ask with search\",\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a64af065",
      "metadata": {
        "id": "a64af065"
      },
      "source": [
        "Creamos nuestro agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cb61652",
      "metadata": {
        "id": "2cb61652"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.utilities import SerpAPIWrapper\n",
        "\n",
        "zero_shot_agent = initialize_agent(\n",
        "    agent=\"zero-shot-react-description\",\n",
        "    tools=[searchTool,math_tool],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    max_iterations=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daf5c947",
      "metadata": {
        "id": "daf5c947"
      },
      "source": [
        "Probamos nuestro agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906d9b78",
      "metadata": {
        "id": "906d9b78"
      },
      "outputs": [],
      "source": [
        "zero_shot_agent(\"Cual es el sueldo actual de Cristiano Ronaldo en pesos chilenos?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}